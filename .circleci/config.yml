# CircleCI 2.0 configuration file
# for ENCODE DNase-seq Pipeline
# Maintainer: Ulugbek Baymuradov

# Defaults and functions
---
defaults: &defaults
  docker:
    - image: circleci/buildpack-deps:xenial-scm
  working_directory: ~/dnase-seq-pipeline

python_defaults: &python_defaults
  docker:
    - image: quay.io/encode-dcc/dnase-seq-pipeline:${CIRCLE_BRANCH}_${CIRCLE_WORKFLOW_ID}
  working_directory: ~/dnase-seq-pipeline

machine_defaults: &machine_defaults
  machine:
    image: circleci/classic:latest
  working_directory: ~/dnase-seq-pipeline

make_tag: &make_tag
  name: make docker image tag
  command: |
    echo "export TAG=quay.io/encode-dcc/${CIRCLE_PROJECT_REPONAME}:${CIRCLE_BRANCH}_${CIRCLE_WORKFLOW_ID}" > ${BASH_ENV}

setup_git_lfs: &setup_git_lfs
  name: install git-lfs for large files
  command: |
    curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
    sudo apt-get install git-lfs
    git lfs install
    git lfs pull

install_jq: &install_jq
  name: install jq for json processing
  command: |
    sudo apt-get install jq

install_samtools: &install_samtools
  name: install samtools for bam comparison
  command: |
    sudo apt-get install samtools -y

run_dups_task: &run_dups_task
  name: run dups task with cromwell/wdl
  command: |
    test/test.sh test/test_task/test_dups.wdl test/test_task/test_dups_input.json quay.io/encode-dcc/dnase-seq-pipeline:template docker

run_filter_task: &run_filter_task
  name: run filter task with cromwell/wdl
  command: |
    test/test.sh test/test_task/test_filter.wdl test/test_task/test_filter_input.json quay.io/encode-dcc/dnase-seq-pipeline:template docker

install_singularity: &install_singularity
  name: install singularity
  command: |
    sudo apt-get update
    sudo apt-get install \
    dh-autoreconf \
    build-essential \
    libarchive-dev \
    squashfs-tools
    wget https://github.com/singularityware/singularity/releases/download/2.6.0/singularity-2.6.0.tar.gz
    tar xvf singularity-2.6.0.tar.gz
    cd singularity-2.6.0
    ./configure --prefix=/usr/local --sysconfdir=/etc
    make
    sudo make install
    singularity --version
# Jobs
version: 2
jobs:
  unittests:
    <<: *python_defaults
    steps:
      - checkout
      - run:
          command: |
            cd src
  build:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - run: *make_tag
      - run:
          name: build image
          command: |
            source ${BASH_ENV}
            echo "pulling template!"
            docker pull quay.io/encode-dcc/dnase-seq-pipeline:template
            docker login -u=${QUAY_ROBOT_USER} -p=${QUAY_ROBOT_USER_TOKEN} quay.io
            docker build --cache-from quay.io/encode-dcc/dnase-seq-pipeline:template --build-arg GIT_COMMIT_HASH=${CIRCLE_SHA1} --build-arg BRANCH=${CIRCLE_BRANCH} --build-arg BUILD_TAG=${TAG} -t $TAG -t quay.io/encode-dcc/dnase-seq-pipeline:template .
            docker push $TAG
            docker push quay.io/encode-dcc/dnase-seq-pipeline:template
            docker logout
          no_output_timeout: 30m
  
  test_dups_docker:
    <<: *machine_defaults
    steps:
      - checkout
      - setup_remote_docker 
      - run: *make_tag
      - run: *install_samtools
      - run: *setup_git_lfs
      - run: *install_jq
      - run: *run_dups_task
      - run:
          name: compare dups step outputs
          command: |
            source ${BASH_ENV}
            source test/test_helper.bash
            expected_marked_bam="test_data/dnase/alignment/expected/marked.bam"
            expected_duplicates_picard="test_data/dnase/alignment/expected/MarkDuplicates.picard"
            output_marked_bam=$(jq -r '.outputs."test_dups.dups.marked_bam"' test_dups_input.metadata.json)
            output_duplicates_picard=$(jq -r '.outputs."test_dups.dups.marked_dup_picard"' test_dups_input.metadata.json)
            [ -f $expected_marked_bam ] || exit 1
            [ -f $expected_duplicates_picard ] || exit 1
            [ -f $output_marked_bam ] || exit 1
            [ -f $output_duplicates_picard ] || exit 1
            cmp_bam $expected_marked_bam $output_marked_bam
            cmp_picard $expected_duplicates_picard $output_duplicates_picard

  test_filter_docker:
    <<: *machine_defaults
    steps:
      - checkout
      - run: *make_tag
      - run: *install_samtools
      - run: *setup_git_lfs
      - run: *install_jq
      - run: *run_filter_task
      - run:
          name: compare filter step outputs
          command: |
            source ${BASH_ENV}
            source test/test_helper.bash
            expected_filtered_bam="test_data/dnase/aggregation/expected/filtered.bam"
            output_marked_bam=$(jq -r '.outputs."test_filter.filter.filtered_bam"' test_dups_input.metadata.json)
            [ -f $expected_marked_bam ] || exit 1
            [ -f $output_marked_bam ] || exit 1
            cmp_bam $expected_marked_bam $output_marked_bam

# Workflow
workflows:
  version: 2
  build_workflow:
    jobs:
      - test_dups_docker
      - test_filter_docker
